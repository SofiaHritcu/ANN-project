{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "#def transformImage(filename):\n",
    "    \n",
    "def getInputs():\n",
    "    imgs = []\n",
    "    for i in range(1,101):\n",
    "        filename = 'test_image_png_'+str(i)+'.png'\n",
    "        img = Image.open(filename).resize((8,8))\n",
    "        imgs.append(img)\n",
    "    pxMatrices = []\n",
    "    for img in imgs:\n",
    "        pxMatrices.append(np.array(img.getdata()))\n",
    "    return pxMatrices\n",
    "        \n",
    "inputs = getInputs()\n",
    "outputs = []\n",
    "for i in range(0,100):\n",
    "    outputs.append('0')\n",
    "outputNames = ['0','1']\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### separating training data from test data 20%-80%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def splitData(inputs, outputs):\n",
    "    np.random.seed(5)\n",
    "    indexes = [i for i in range(len(inputs))]\n",
    "    trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace = False)\n",
    "    testSample = [i for i in indexes  if not i in trainSample]\n",
    "\n",
    "    trainInputs = [inputs[i] for i in trainSample]\n",
    "    trainOutputs = [outputs[i] for i in trainSample]\n",
    "    testInputs = [inputs[i] for i in testSample]\n",
    "    testOutputs = [outputs[i] for i in testSample]\n",
    "    \n",
    "    return trainInputs, trainOutputs, testInputs, testOutputs\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**normalize data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalisation(trainData, testData):\n",
    "    scaler = StandardScaler()\n",
    "    if not isinstance(trainData[0], list):\n",
    "        #encode each sample into a list\n",
    "        trainData = [[d] for d in trainData]\n",
    "        testData = [[d] for d in testData]\n",
    "        \n",
    "        scaler.fit(trainData)  #  fit only on training data\n",
    "        normalisedTrainData = scaler.transform(trainData) # apply same transformation to train data\n",
    "        normalisedTestData = scaler.transform(testData)  # apply same transformation to test data\n",
    "        \n",
    "        #decode from list to raw values\n",
    "        normalisedTrainData = [el[0] for el in normalisedTrainData]\n",
    "        normalisedTestData = [el[0] for el in normalisedTestData]\n",
    "    else:\n",
    "        scaler.fit(trainData)  #  fit only on training data\n",
    "        normalisedTrainData = scaler.transform(trainData) # apply same transformation to train data\n",
    "        normalisedTestData = scaler.transform(testData)  # apply same transformation to test data\n",
    "    return normalisedTrainData, normalisedTestData\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    **ANN Classification (logic)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "classifier = neural_network.MLPClassifier()\n",
    "\n",
    "def training(classifier, trainInputs, trainOutputs):\n",
    "    # step4: training the classifier\n",
    "    # identify (by training) the classification model\n",
    "    classifier.fit(trainInputs, trainOutputs)\n",
    "\n",
    "def classification(classifier, testInputs):\n",
    "    # step5: testing (predict the labels for new inputs)\n",
    "    # makes predictions for test data \n",
    "    computedTestOutputs = classifier.predict(testInputs)\n",
    "\n",
    "    return computedTestOutputs\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### leran model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b0c3fcc075ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrainInputsFlatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtestInputsFlatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestInputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrainInputsNormalised\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestInputsNormalised\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalisation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainInputsFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestInputsFlatten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-dd61924196f0>\u001b[0m in \u001b[0;36mnormalisation\u001b[1;34m(trainData, testData)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mnormalisedTestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormalisedTestData\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#  fit only on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mnormalisedTrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# apply same transformation to train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mnormalisedTestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# apply same transformation to test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anul ii\\sem2\\ai\\ai_3_4_5\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anul ii\\sem2\\ai\\ai_3_4_5\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mTransformer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \"\"\"\n\u001b[1;32m--> 698\u001b[1;33m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m                         force_all_finite='allow-nan')\n",
      "\u001b[1;32md:\\anul ii\\sem2\\ai\\ai_3_4_5\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n\u001b[0m\u001b[0;32m    592\u001b[0m                              \u001b[1;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                              % (n_features, array.shape, ensure_min_features,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(80, 0)) while a minimum of 1 is required by StandardScaler."
     ],
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(80, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "        \n",
    "\n",
    "trainInputs, trainOutputs, testInputs, testOutputs = splitData(inputs, outputs)\n",
    "def flatten(mat):\n",
    "    x = []\n",
    "    for line in mat:\n",
    "        if isinstance(line,list):\n",
    "            for el in line:\n",
    "                x.append(el)\n",
    "    return x \n",
    "\n",
    "trainInputsFlatten = [flatten(el) for el in trainInputs]\n",
    "testInputsFlatten = [flatten(el) for el in testInputs]\n",
    "trainInputsNormalised, testInputsNormalised = normalisation(trainInputsFlatten, testInputsFlatten)\n",
    "classifier = neural_network.MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=100, solver='sgd', verbose=10, random_state=1, learning_rate_init=.1)\n",
    "\n",
    "training(classifier, trainInputsNormalised, trainOutputs)\n",
    "predictedLabels = classification(classifier, testInputsNormalised)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predict classes for test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evalMultiClass(realLabels, computedLabels, labelNames):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    confMatrix = confusion_matrix(realLabels, computedLabels)\n",
    "    acc = sum([confMatrix[i][i] for i in range(len(labelNames))]) / len(realLabels)\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    for i in range(len(labelNames)):\n",
    "        precision[labelNames[i]] = confMatrix[i][i] / sum([confMatrix[j][i] for j in range(len(labelNames))])\n",
    "        recall[labelNames[i]] = confMatrix[i][i] / sum([confMatrix[i][j] for j in range(len(labelNames))])\n",
    "    return acc, precision, recall, confMatrix\n",
    "acc, precision, recall, cm = evalMultiClass(np.array(testOutputs), predictedLabels, outputNames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### calculate error\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('acc: ', acc)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}